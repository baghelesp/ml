{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Name : Shivam Baghele\n",
        "#### Roll No : A3 - 63\n",
        "#### Subject : Machine Learning\n",
        "#### Practical 07"
      ],
      "metadata": {
        "id": "EQhozOH9Hs9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EoshbAy3Hs53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XOR prolem solving using BPN."
      ],
      "metadata": {
        "id": "QFnsxTzf9zNP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KE23qBG9wlt",
        "outputId": "22fdbabd-9250-4aa1-bb5c-8a7f64b50c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Error = 0.4965166892314006\n",
            "weights_input_hidden =\n",
            "[[0.37339358 0.94964754 0.73195763 0.59763436]\n",
            " [0.15495067 0.15509735 0.0580513  0.8651894 ]]\n",
            "bias_hidden =[[-2.76182569e-03 -2.96946207e-03 -9.15451746e-05 -3.75262487e-03]]\n",
            "weights_hidden_output =\n",
            "[[0.59056324]\n",
            " [0.69653048]\n",
            " [0.00954003]\n",
            " [0.95801566]] \n",
            "bias_output=[[-0.01900371]]\n",
            "\n",
            "Epoch 1000: Error = 0.4873148164354445\n",
            "weights_input_hidden =\n",
            "[[ 0.31177933  0.94062471  0.81339024  1.41419855]\n",
            " [ 0.09488521  0.27950574 -0.00462046  1.4999884 ]]\n",
            "bias_hidden =[[-0.05507398 -0.00333484  0.01545471  0.20046702]]\n",
            "weights_hidden_output =\n",
            "[[ 0.11045767]\n",
            " [ 0.1655882 ]\n",
            " [-0.56112574]\n",
            " [ 1.16889131]] \n",
            "bias_output=[[-0.73550354]]\n",
            "\n",
            "Epoch 2000: Error = 0.4184354737536522\n",
            "weights_input_hidden =\n",
            "[[0.36779611 0.96430335 1.13344296 3.11495718]\n",
            " [0.19899927 0.31711165 0.14056611 2.97742039]]\n",
            "bias_hidden =[[-0.05755547 -0.05299421 -0.04552133 -0.39235056]]\n",
            "weights_hidden_output =\n",
            "[[-0.34045886]\n",
            " [-0.49736264]\n",
            " [-1.22905621]\n",
            " [ 2.99254633]] \n",
            "bias_output=[[-1.13037308]]\n",
            "\n",
            "Epoch 3000: Error = 0.31041826822937113\n",
            "weights_input_hidden =\n",
            "[[0.57105838 1.05419763 1.37985837 4.53197151]\n",
            " [0.90426276 0.85401884 1.02440878 4.23998455]]\n",
            "bias_hidden =[[-0.39976833 -0.79698489 -1.36666502 -1.05017224]]\n",
            "weights_hidden_output =\n",
            "[[-1.28685276]\n",
            " [-1.68264261]\n",
            " [-2.59443618]\n",
            " [ 4.90696645]] \n",
            "bias_output=[[-1.09249768]]\n",
            "\n",
            "Epoch 4000: Error = 0.17220908920414524\n",
            "weights_input_hidden =\n",
            "[[0.73047993 1.37011235 2.05811565 5.22929528]\n",
            " [1.15115372 1.22290734 1.9166935  5.08573886]]\n",
            "bias_hidden =[[-0.90321251 -1.73097529 -2.95210022 -1.83105872]]\n",
            "weights_hidden_output =\n",
            "[[-2.04549307]\n",
            " [-2.7261905 ]\n",
            " [-4.21474175]\n",
            " [ 6.485658  ]] \n",
            "bias_output=[[-1.3865258]]\n",
            "\n",
            "Epoch 5000: Error = 0.11406009919321453\n",
            "weights_input_hidden =\n",
            "[[0.78722772 1.54726131 2.45117786 5.56694124]\n",
            " [1.16143505 1.39296862 2.33345369 5.47989197]]\n",
            "bias_hidden =[[-1.07228599 -2.14537569 -3.6595091  -2.18837653]]\n",
            "weights_hidden_output =\n",
            "[[-2.33234636]\n",
            " [-3.15971769]\n",
            " [-4.98325161]\n",
            " [ 7.36009045]] \n",
            "bias_output=[[-1.74478483]]\n",
            "\n",
            "Epoch 6000: Error = 0.08757471533873834\n",
            "weights_input_hidden =\n",
            "[[0.81084502 1.64901462 2.67183837 5.76201758]\n",
            " [1.15022581 1.4987132  2.56684164 5.69922986]]\n",
            "bias_hidden =[[-1.14468511 -2.37670387 -4.04162472 -2.36728252]]\n",
            "weights_hidden_output =\n",
            "[[-2.47588109]\n",
            " [-3.38934162]\n",
            " [-5.41263352]\n",
            " [ 7.8901716 ]] \n",
            "bias_output=[[-1.99814288]]\n",
            "\n",
            "Epoch 7000: Error = 0.07253990235706186\n",
            "weights_input_hidden =\n",
            "[[0.82349967 1.71946742 2.81817395 5.89336787]\n",
            " [1.13783148 1.57451562 2.72133183 5.84406501]]\n",
            "bias_hidden =[[-1.18509284 -2.53225389 -4.29023145 -2.47782383]]\n",
            "weights_hidden_output =\n",
            "[[-2.56525682]\n",
            " [-3.53908792]\n",
            " [-5.69928207]\n",
            " [ 8.25862092]] \n",
            "bias_output=[[-2.18337517]]\n",
            "\n",
            "Epoch 8000: Error = 0.06276812529332143\n",
            "weights_input_hidden =\n",
            "[[0.83128658 1.77322745 2.92536637 5.99048325]\n",
            " [1.12669574 1.63331464 2.83433136 5.94985303]]\n",
            "bias_hidden =[[-1.21120492 -2.6479463  -4.47024963 -2.55515037]]\n",
            "weights_hidden_output =\n",
            "[[-2.62809688]\n",
            " [-3.64846467]\n",
            " [-5.91103429]\n",
            " [ 8.5375202 ]] \n",
            "bias_output=[[-2.32679215]]\n",
            "\n",
            "Epoch 9000: Error = 0.0558479189754639\n",
            "weights_input_hidden =\n",
            "[[0.83648786 1.81665561 3.00895216 6.06670469]\n",
            " [1.11696262 1.68121953 2.92234309 6.03217702]]\n",
            "bias_hidden =[[-1.22963679 -2.73942638 -4.60953679 -2.61353133]]\n",
            "weights_hidden_output =\n",
            "[[-2.67567611]\n",
            " [-3.73397967]\n",
            " [-6.07752321]\n",
            " [ 8.76050135]] \n",
            "bias_output=[[-2.44282713]]\n",
            "\n",
            "-------------------------------------------------------------------------\n",
            "Predicted XOR outputs:\n",
            "[[0.05561616]\n",
            " [0.95121366]\n",
            " [0.95219406]\n",
            " [0.05040275]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "# sigmoid derivative\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# XOR data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "#Neural Network architecture\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(42)\n",
        "weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))\n",
        "bias_hidden = np.zeros((1, hidden_size))\n",
        "weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))\n",
        "bias_output = np.zeros((1, output_size))\n",
        "\n",
        "# Training\n",
        "epochs = 10000\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "    output_layer_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
        "    predicted_output = sigmoid(output_layer_input)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = y - predicted_output\n",
        "\n",
        "    # Backpropagation\n",
        "    d_output = error * sigmoid_derivative(predicted_output)\n",
        "    error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
        "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # Update weights and biases\n",
        "    weights_hidden_output += hidden_output.T.dot(d_output) * learning_rate\n",
        "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate\n",
        "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Display the error at certain intervals\n",
        "    if epoch % 1000 == 0:\n",
        "        mean_error = np.mean(np.abs(error))\n",
        "        print(f\"Epoch {epoch}: Error = {mean_error}\")\n",
        "        print(f\"weights_input_hidden =\\n{weights_input_hidden}\")\n",
        "        print(f\"bias_hidden ={bias_hidden}\")\n",
        "        print(f\"weights_hidden_output =\\n{weights_hidden_output} \")\n",
        "        print(f\"bias_output={bias_output}\")\n",
        "        print()\n",
        "\n",
        "\n",
        "# Testing the trained model\n",
        "test_input = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "predicted_output = sigmoid(np.dot(sigmoid(np.dot(test_input, weights_input_hidden) + bias_hidden), weights_hidden_output) + bias_output)\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "print(\"Predicted XOR outputs:\")\n",
        "print(predicted_output)\n",
        "\n"
      ]
    }
  ]
}